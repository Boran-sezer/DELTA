import streamlit as st
from groq import Groq
import firebase_admin
from firebase_admin import credentials, firestore
import base64, json, hashlib
from datetime import datetime

# --- INITIALISATION FIREBASE ---
if not firebase_admin._apps:
    try:
        encoded = st.secrets["firebase_key"]["encoded_key"].strip()
        decoded_json = base64.b64decode(encoded).decode("utf-8")
        cred = credentials.Certificate(json.loads(decoded_json))
        firebase_admin.initialize_app(cred)
    except Exception as e:
        st.error(f"Erreur Firebase : {e}")
        st.stop()

db = firestore.client()

# --- INITIALISATION GROQ ---
client = Groq(api_key="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")

USER_ID = "monsieur_sezer"

# --- UTILS MÃ‰MOIRE ---
def hash_text(text: str) -> str:
    return hashlib.sha256(text.encode("utf-8")).hexdigest()

def is_memory_worthy(text: str) -> bool:
    blacklist = ["salut", "ok", "mdr", "lol", "?", "oui", "non"]
    return len(text.strip()) >= 10 and text.lower().strip() not in blacklist

# --- INTERFACE ---
st.set_page_config(page_title="DELTA AGI", page_icon="ðŸŒ", layout="wide")
st.title("ðŸŒ DELTA : SystÃ¨me AGI")

mem_ref = db.collection("users").document(USER_ID).collection("memory")

# --- RÃ‰CUPÃ‰RATION DU CONTEXTE ---
def get_recent_memories(limit=10):
    try:
        memories = mem_ref.order_by("created_at", direction=firestore.Query.DESCENDING).limit(limit).stream()
        return [m.to_dict() for m in memories]
    except Exception:
        return []

context_list = get_recent_memories()

with st.sidebar:
    st.header("ðŸ§  MÃ©moire Vive")
    for m in context_list:
        st.caption(f"[{m.get('category')}] {m.get('content')}")
    if st.button("ðŸ”„ Actualiser"):
        st.experimental_rerun()

if "messages" not in st.session_state:
    st.session_state.messages = []

# --- AFFICHAGE DU CHAT ---
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# --- PROCESSUS PRINCIPAL ---
if prompt := st.chat_input("En attente de vos ordres, Monsieur Sezer..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)

    # 1. ANALYSE ET STOCKAGE
    if is_memory_worthy(prompt):
        m_hash = hash_text(prompt)
        ref = mem_ref.document(m_hash)
        if not ref.get().exists:
            try:
                analysis = client.chat.completions.create(
                    model="llama-3.3-70b-versatile",
                    messages=[
                        {"role": "system", "content": "Tu es une IA forte. CatÃ©gorise en JSON : {'category': '...'} "},
                        {"role": "user", "content": f"Donne une catÃ©gorie courte pour : {prompt}"}
                    ],
                    response_format={"type": "json_object"}
                )
                cat = json.loads(analysis.choices[0].message.content).get("category", "info")
                ref.set({
                    "category": cat,
                    "content": prompt,
                    "created_at": datetime.utcnow()
                })
                st.success("ðŸ§¬ Souvenir enregistrÃ©.")
            except Exception as e:
                st.warning(f"MÃ©moire non mise Ã  jour ({e})")

    # 2. RÃ‰CUPÃ‰RATION CONTEXTE Ã€ JOUR
    context_list = get_recent_memories()

    # 3. RÃ‰PONSE JARVIS
    with st.chat_message("assistant"):
        context_str = "\n".join([f"- {m['content']}" for m in context_list])
        sys_instr = (
            f"Tu es Jarvis, l'IA de Monsieur Sezer. "
            f"Tes souvenirs rÃ©cents sont : {context_str}. "
            "Sois concis, brillant et direct. Ne mentionne pas que tu es une IA."
        )

        try:
            response = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "system", "content": sys_instr}] + st.session_state.messages[-5:]
            ).choices[0].message.content

            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})
        except Exception as e:
            st.error(f"Erreur Groq : {e}")

# => supprime st.experimental_rerun()
