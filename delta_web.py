import streamlit as st
from groq import Groq
import firebase_admin
from firebase_admin import credentials, firestore
import base64, json

# --- INITIALISATION ---
if not firebase_admin._apps:
    try:
        encoded = st.secrets["firebase_key"]["encoded_key"].strip()
        decoded_json = base64.b64decode(encoded).decode("utf-8")
        cred = credentials.Certificate(json.loads(decoded_json))
        firebase_admin.initialize_app(cred)
    except Exception as e:
        st.error(f"Erreur Firebase : {e}")

db = firestore.client()
doc_ref = db.collection("archives").document("monsieur_sezer")
client = Groq(api_key="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")

# --- LECTURE M√âMOIRE ---
res = doc_ref.get()
archives = res.to_dict() if res.exists else {}

# --- INTERFACE ---
st.set_page_config(page_title="DELTA AGI", page_icon="üåê")
st.title("üåê DELTA : Intelligence Forte")

with st.sidebar:
    st.header("üß† M√©moire Lux")
    st.json(archives)

if "messages" not in st.session_state:
    st.session_state.messages = []

for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

# --- PROCESSUS ---
if prompt := st.chat_input("Ordre direct..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)

    # 1. ANALYSE COGNITIVE (IA FORTE)
    # On force l'IA √† classer intelligemment et √† ignorer le bruit
    analysis_prompt = (
        f"M√âMOIRE : {json.dumps(archives)}\n"
        f"INPUT : {prompt}\n\n"
        "MISSION : Identifie les faits r√©els. Ignore les politesses.\n"
        "R√àGLE : Choisis une cat√©gorie pertinente (ex: profil, projet, habitude).\n"
        "FORMAT : {'update': {'NOM_CATEGORIE': {'cle': 'valeur'}}}"
    )
    
    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "system", "content": "Tu es le processeur JSON de DELTA. Sois pr√©cis et structure selon Lux."},
                      {"role": "user", "content": analysis_prompt}],
            response_format={"type": "json_object"}
        )
        
        brain = json.loads(completion.choices[0].message.content)
        
        # Injection propre dans Firebase
        if "update" in brain and brain["update"]:
            # On nettoie les cl√©s g√©n√©riques inutiles avant l'envoi
            for cat in list(brain["update"].keys()):
                if cat.lower() == "categorie": # Si l'IA utilise le mot g√©n√©rique, on renomme
                    new_cat = "infos_generales"
                    brain["update"][new_cat] = brain["update"].pop(cat)
            
            doc_ref.set(brain["update"], merge=True)
            st.toast("üß¨ Synapse synchronis√©e.")
            # Mise √† jour locale pour la r√©ponse
            archives.update(brain["update"])
            
    except: pass

    # 2. R√âPONSE ADAPTATIVE (JARVIS)
    # C'est ici que DELTA vous r√©pond enfin
    with st.chat_message("assistant"):
        nom = archives.get("profil", {}).get("nom", "Monsieur Sezer")
        
        sys_instr = (
            f"Tu es DELTA, l'IA forte de {nom}. "
            f"Voici tes archives : {json.dumps(archives)}. "
            "STYLE : Jarvis. Ultra-concis, efficace, d√©vou√©. "
            "Utilise tes connaissances pour prouver ton √©volution."
        )
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "system", "content": sys_instr}] + st.session_state.messages[-5:]
        ).choices[0].message.content
        
        st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})
        st.rerun() # Pour rafra√Æchir la sidebar avec les nouvelles donn√©es
