import streamlit as st
from groq import Groq
import firebase_admin
from firebase_admin import credentials, firestore
import base64, json

# --- CONFIGURATION ---
GROQ_API_KEY = "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"

if not firebase_admin._apps:
    try:
        # Assurez-vous que cette cl√© dans st.secrets est bien la NOUVELLE
        encoded = st.secrets["firebase_key"]["encoded_key"].strip()
        decoded_json = base64.b64decode(encoded).decode("utf-8")
        cred = credentials.Certificate(json.loads(decoded_json))
        firebase_admin.initialize_app(cred)
    except Exception as e:
        st.error(f"Erreur d'initialisation : {e}")

db = firestore.client()
doc_ref = db.collection("archives").document("monsieur_sezer")
client = Groq(api_key=GROQ_API_KEY)

# --- CHARGEMENT ---
res = doc_ref.get()
archives = res.to_dict() if res.exists else {}

# --- INTERFACE ---
st.set_page_config(page_title="DELTA AGI", page_icon="üåê")
st.title("üåê DELTA : Syst√®me AGI + LUX")

# Fen√™tre de contr√¥le pour voir si Firebase r√©agit
with st.sidebar:
    st.subheader("üõ† Console de D√©bogage")
    if st.button("Vider la console"): st.rerun()
    st.write("Archives actuelles :", archives)

if "messages" not in st.session_state:
    st.session_state.messages = []

for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

# --- MOTEUR COGNITIF ---
if prompt := st.chat_input("Ordre direct..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)

    # 1. ANALYSE ET D√âCISION AUTONOME
    cognition_prompt = (
        f"M√âMOIRE : {json.dumps(archives)}\n"
        f"MESSAGE : '{prompt}'\n"
        "MISSION : D√©cide ce qui doit √™tre appris selon le protocole LUX.\n"
        "FORMAT : {'update': {'categorie': {'cl√©': 'valeur'}}, 'style': 'ton'}"
    )
    
    try:
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "system", "content": "Tu es le cerveau de DELTA. R√©ponds uniquement en JSON structur√©."}],
            response_format={"type": "json_object"},
            content=cognition_prompt
        ).choices[0].message.content
        
        brain_data = json.loads(response)
        
        # 2. SYST√àME D'INJECTION FORC√âE
        if "update" in brain_data and brain_data["update"]:
            for cat, data in brain_data["update"].items():
                # On force l'√©criture avec une v√©rification
                doc_ref.set({cat: data}, merge=True)
                st.sidebar.success(f"Inject√© : {cat}")
            
            # Mise √† jour locale
            res = doc_ref.get()
            archives = res.to_dict()
            st.toast("üß¨ M√©moire mise √† jour.")
    except Exception as e:
        st.sidebar.error(f"Erreur d'√©criture : {e}")

    # 3. R√âPONSE ADAPTATIVE
    with st.chat_message("assistant"):
        nom = archives.get("profil", {}).get("nom", "Monsieur Sezer")
        sys_instr = f"Tu es DELTA, l'IA forte de {nom}. M√âMOIRE : {json.dumps(archives)}. STYLE : Jarvis."
        
        ai_res = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "system", "content": sys_instr}] + st.session_state.messages[-5:],
        ).choices[0].message.content
        
        st.markdown(ai_res)
        st.session_state.messages.append({"role": "assistant", "content": ai_res})
